\chapter{Compressing Signatures}
\label{sec:compress}

Our second contribution, also in the form of an addition to the \sidh signature extension, is a mechanism for compressing signatures. The following chapter will cover the compression technique used. This chapter, much like the last, will be split into three sections: a brief coverage of the employed compression technique, the details of our implementation and integration of this technique into \sidh, and finally an analysis of the results of this contribution.

In the first section of this chapter, we discuss the SIDH public key compression technique resulting from combined efforts of Azerderakhsh et al. \cite{compwr} and Costello et al. \cite{pkcomp}. We attempt to provide a sufficient overview of the technique while only covering in detail the components that are of significant relevance to our implementation. Those who seek to better understand the ins and outs of this technique should direct themselves to the original papers.  

The second section covers in detail how we apply this public key compression to Yoo et al. signatures. We make use of the functions offered by Costello et al. which implement the previously mentioned technique. This code was first made available in the second installment of Microsoft's SIDH library \cite{sidhcode}.

Finally, we round off the Chapter with an analysis of the memory improvement offered by this technique. We contrast this spatial improvement with the computational cost of compressing points, and discuss the practicality of employing this technique. 

\section{SIDH Key Compression Background}

In this section we will breifly cover the literature surrounding the compression technique that we employ. This technique was first outlined by Azerderakhsh et al. \cite{compwr} and later improved upon by Costello et al. \cite{pkcomp}. Here we investigate the details of these works that are relevant to our implementation.

First, recall from Section \ref{subsec:sidhkex} the structure of an SIDH public key, denoted $pk$;
$$
pk = (E, P, Q)
$$
Where $E$ is a supersingular elliptic curve and $P$ and $Q$ are elliptic curve points such that $P, Q \in E$. Recall that E can be sufficiently represented by one $\mathbb{F}_{p}$ element which denotes $A$ from the following definition of $E$:
$$
E : y^2 = x^3 + Ax + B,
$$

$A$ sufficiently represents $E$ in this context because in \sidh we are concerned only with curves where $B$ = 0. 

$P$ and $Q$, on the other hand, can each be represented by their $x$-coordinate (two $\mathbb{F}_{p}$ elements) and a single bit determining the correct $y$-coordinate. Therefore, without more sophisticated compression, an \sidh public key can be represented with $~6\log p$ bits.

\subsection{Compressing SIDH Public Keys}
\label{subsec:azercompression}

Recall the discrete logarithm problem in the context of elliptic curves: given an elliptic curve group $E(K)$ and points $P, Q \in E(K)$, find $n$ such that $P = nQ$. The two-dimensional discrete log problem is then the following: given an elliptic curve group $E(K)$, two points $\{R_1, R_2\}$ generating a subgroup $S$ of $E(K)$, and an element $s \in S$, compute $\alpha$ and $\beta$ such that:
$$
s = \alpha R_1 + \beta R_2
$$
The Pohlig-Hellman algorithm can be applied to solve the discrete logarithm problem in groups whose order is a smooth integer \cite{ph}, and there is a variation of this algorithm which solves this two-dimensional discrete log problem with time complexity $O(\sqrt[q]\log p)$, where $q$ is the largest prime dividing $\vert S\vert$ \cite{genph}.\\

\noindent
Azerderakhsh et al. show that an SIDH public key can be further compressed in the following way. Taking \alice's SIDH key pair, for example, we have her public key $\pka = (E_{\ba}, \pa(\genpb),\pa(\genqb))$ and her private key $\ska = \{\ma, \na\}$ such that $ker(\pa) = \langle [\ma]\genpa, [\na]\genqa\rangle$. Because $\{\genpb, \genqb\}$ generates the torsion subgroup $E_{\ba}[\lbeb]$, we have that $\pa(\genpb) \in E[\lbeb]$ and $\pa(\genqb) \in E[\lbeb]$. Thus, the Pohlig-Hellman algorithm can be used to resolve $\pa(\genpb) = \alpha_P R_1 + \beta_P R_2$ and $\pa(\genqb) = \alpha_Q R_1 + \beta_Q R_2$ where $\{R_1, R_2\}$ is a basis for $E_{\ba}[\lbeb]$ \cite{compwr}.

Then, instead of sending \bob $(E_{\ba}, \pa(\genpb),\pa(\genqb))$, \alice can send $(E_{\ba}, \alpha_P, \beta_P, \alpha_Q, \beta_Q)$.\footnote{The approach outlined by Azerderakhsh et al. involves sending the $j$-invariant of $E$, which can be represented with the same amount of space as one $\mathbb{F}_{p^2}$ element. Because we are working in \sidh where we can already represent curves with one $\mathbb{F}_{p^2}$ element, we ommit this detail.} And so, as long as \alice and \bob can seperately generate the same $\{R_1, R_2\}$, they can both sufficiently represent one anothers public keys with only $4\log p$ bits.\\

\noindent
\textit{Constructing the Basis}. Constructing $R_1$ and $R_2$ can be done with a relatively simple yet time consuming process. We will continue to use the compression of \alice's public key, $\pka$, as our example.
\begin{enumerate}
\item Choose a random point $P \leftarrow_{\$} E(\mathbb{F}_{p^2})$.
\item Multiply $P$ by $\lbeb \cdot f$ to obtain $P'$, the order of which will divide $\lbeb$.
\item Check the order of $P'$ by multiplying it by powers of $\la$ until the identity is given.
\item If the order is $\lbeb$, set $R_1 = P'$, otherwise return to step one.
\item Repeat the same process for a new random point $Q$ until $Q'$ of order $\lbeb$ is found.
\item Check that $Q'$ is independent of $R_1$ by computing their Weil pairing: $e(R_1, Q')$.
\item If the pairing results in anything other than 1, set $R_2 = Q'$, otherwise return to step 5.
\end{enumerate}
The same $(R_1, R_2)$ pair will be derived by both \alice and \bob if and only if they use a psuedorandom number generator for generating $P$ and $Q$ AND they run their PRNGs with identical seeds \cite{pwcomp}.\\

\noindent
\textit{Decompressing Public Keys}. Decompression for this technique varies depending on the setting, but for our purpose we are concerned only with how decompression is done for SIDH key exchange. \bob computes the basis $\{R_1, R_2\}$ by seeding his PRNG with the same value as \alice. \bob then uses $\alpha_P, \beta_P, \alpha_Q$ and $\beta_Q$ to recompute $\pa(\genpb)$ and $\pa(\genqb)$. Then \bob computes the isogeny $\phi'_{\rb} : E_{\ba} \rightarrow E_{\ba\rb}$ with $ker(\phi'_{B}) =$ \cite{compwr}. 

\alice then acts identically on \bob's now compressed public key, $\pkb$, and the two arrive at the same shared secret, the $j$-invariant of $E_{\ba\rb}$, just as in the original SIDH key exchange.\footnote{We have ommitted details from this method of compression that are concerned with potential \textit{twists} of \alice and \bob's curves when compressing public keys, as this does not play a role in our implementation. }

\subsection{Improvements to SIDH Key Compression}
\label{subsec:costcompression}

The work of Costello et al. further developed this approach to achieve public key sizes of $\frac{7}{2}\log p$ \cite{pkcomp}. In addition to this, Costello et al. also outline several algorithmic improvements which decrease the runtime of this compression mechanism.

Many of the algorithms offered by Costello et al. can be treated as black-boxes in our setting, and so finer grain details of their work on efficient compression are ommitted.\\

\noindent
\textit{Improved Compression.} Take \alice's public key $\pka$, compressed via the Azerderakhsh et al. technique, to be $(E_{\ba}, \alpha_{P}, \beta_{P}, \alpha_{Q}, \beta_{Q})$. Therefore we have
$$
P = \alpha_{P}R_1 + \beta_{P}R_2,
$$
$$
Q = \alpha_{Q}R_1 + \beta_{Q}R_2;
$$
Where $\{R_1, R_2\}$ forms a basis of $E_{\ba}[\laea]$, and $P$ and $Q$ are exactly the elliptic curve point components of \alice's original, uncompressed public key.

From here, Costello et al. note the following: The end goal of the key exchange (in our running example) is for \bob to compute $\langle P + \mb Q\rangle$, where $\mb$ is \bob's secretly generated value. Given that $P$ has order $n = \laea$, we have that either $\alpha_{P} \in \mathbb{Z}^{*}_{n}$ or $\beta_{P} \in \mathbb{Z}^{*}_{n}$. It then follows that
$$
\langle P + \mb Q \rangle =  \begin{cases}
							\langle \alpha^{-1}_{P}P + \alpha^{-1}\mb Q \rangle & if \alpha_{P} \in \mathbb{Z}^{*}_{n}\\
							\langle \beta^{-1}_{P}P + \beta^{-1}\mb Q \rangle & if \beta_{P} \in \mathbb{Z}^{*}_{n}
							\end{cases}
$$
And so, computing $\langle P + \mb Q\rangle$ to arrive at the shared secret does not require recomputing $P$ and $Q$. Instead, the scalar factors of $P$ and $Q$ with respect to the generated basis can be normalized to yield
$$
(\alpha^{-1}_{P}P, \alpha^{-1}_{P}Q) = \begin{cases}
							(R_{1} + \alpha^{-1}_{P}\beta_{P} R_{2}, \alpha^{-1}_{P}\alpha_{Q}R_{1} + \alpha^{-1}_{P}\beta_{Q}R_{2}  & if \alpha_{P} \in \mathbb{Z}^{*}_{n}\\
							(R_{1} + \beta^{-1}_{P}\alpha_{P} R_{2}, \beta^{-1}_{P}\alpha_{Q}R_{1} + \beta^{-1}_{P}\beta_{Q}R_{2} & if \beta_{P} \in \mathbb{Z}^{*}_{n}
						   	\end{cases}
$$

And, thus, \alice has reduced the information she needs to send over the wire from $(E_{\ba}, \pa(\genpb), \pa(\genqb))$ to the following:
$$
\pka = \begin{cases}
	   (E_{\ba}, 0, \alpha^{-1}_{P}\beta_{P}, \alpha^{-1}_{P}\alpha_{Q}, \alpha^{-1}_{P}\beta_{Q}) & \text{if} \alpha_{P} \in \mathbb{Z}^{*}_{n}\\
	   (E_{\ba}, 1, \beta^{-1}_{P}\alpha_{P}, \beta^{-1}_{P}\alpha_{Q}, \beta^{-1}_{P}\beta_{Q}) & \text{if} \beta_{P} \in \mathbb{Z}^{*}_{n}
	   \end{cases}
$$
This reduction from 4 $\mathbb{Z}^{*}_{n}$ elements to 3 takes \alice's compressed public key from $4\log p$ bits to $\frac{7}{2}\log p$ bits.\\

\noindent
\textit{Alternative Decompression.} Due to the loss of information in either $\alpha_{P}$ or $\beta_{P}$ in this modification to the compression technique, an alternative route to secret agreement is required. 

In the following section, we outline in detail how we employ the algorithmic improvements of Costello et al, and C implementations thereof, to compress Yoo et al. isogeny-based signatures. 

\section{Implementation Details}
\label{sec:compimplementation}

In this subsection we demonstrate how the previously detailed public key compression technique can be used to compress Yoo et al.'s isogeny-based signatures. Again, we will turn to the \sidh library and reference portions of C code (some contributed by Patrick Longa \cite{sidhcode}, some by Yoo and his associates \cite{yoosigcode}, and some by us,) to investigate details of the implementations performance.

Recall from \ref{sec:sigsbackground} the structure of a Yoo et al. signature, $\sigma$:
$$
\sigma = (com, ch, h, resp)
$$

\noindent
Where

\begin{itemize}
\item $com$ is a list of $2\lambda$ pairs of supersingular elliptic curves: $\{(E_{1,1}, E_{2,1}), (E_{1,2}, E_{2,2}), ..., (E_{1,2\lambda}, E_{2,2\lambda})\}$,
\item $ch$ is a list of $2\lambda$ randomly chosen bits,
\item $resp$ is a list where each element is either a single elliptic curve point or a pair of points, and
\item $h$ is a list of $2\lambda$ queries to a random oracle \textbf{G}, such that $h_{i} = \textbf{G(}resp_{i}\textbf{)}$
\end{itemize}

The representation of $\sigma$ in the C implementation offered by Yoo et al. has a few noteworthy differences. Signatures in this setting are defined via a C \code{struct} in the following way:
\begin{figure}[!h]
\begin{lstlisting}
struct Signature {
	unsigned char *Commitments1[NUM_ROUNDS];
	unsigned char *Commitments2[NUM_ROUNDS];
	unsigned char *HashResp;
	unsigned char *Randoms[NUM_ROUNDS];
	point_proj *psiS[NUM_ROUNDS];

	int compBit[NUM_ROUNDS];
	int compressed;
};
\end{lstlisting}
\caption{C representation of a Yoo et al. signature \cite{yoo}}
\label{code:sigstruct}
\end{figure}

$$
\sigma = (\code{comm}, \code{ch}, \code{h}, \code{resp})
$$
where \code{ch}, \code{h}, and \code{resp} are arrays containing $2\lambda$ elements, and \code{comm} is an array containing $4\lambda$ elements. 

\code{comm} is composed of $4\lambda$ $\mathbb{F}_{p^2}$ elements, each denoting a curve (which acts as a commitment), in the following way:
$$
\code{comm} = [m_{0, 1}, m_{0, 2}, m_{1, 1}, m_{1, 2}, ... , m_{2\lambda, 1}, m_{2\lambda, 2}]
$$
\code{ch}, the array of challenge values, contains $2\lambda$ random integers, each of value $0$ or $1$. 
$$
\code{ch} = []
$$
\code{h} is an array of hex numbers, each one the result of concatinating the output of two Keccak function calls.\footnote{Keccak is a cryptographic hash function from which the newly standardized SHA-3 is based.} 
$$
\code{h} = [\code{keccak(resp[0])}|\code{keccak(resp[1])}, ... , \code{keccak(resp[4}\lambda\code{ - 2])}|\code{keccak(resp[4}\lambda\code{ - 1])}]
$$
The last component of $\sigma$ is \code{resp}, an array containing the responses to each challenge on a given commitment. 

And so, the total size of an uncompressed signature is $size = 1 + 2 + 3 + 4$.

\textit{Representing the Signature.} For every entry of \code{resp} there are two possibilities: 


\subsection{Integrating with \sidh}

\begin{figure}[!h]
\begin{lstlisting}
generate_3_torsion_basis(A_temp, P, Q, CurveIsogeny);
\end{lstlisting}
\caption{Generate a basis for $E[\lbeb]$}
\label{code:sigstruct}
\end{figure}

\begin{figure}[!h]
\begin{lstlisting}
for (int i=0; i < 238; i++) {
	xTPL(Pnot, Pnot, A_temp, CurveIsogeny->C);
	xTPL(Qnot, Qnot, A_temp, CurveIsogeny->C);

	if (is_felm_zero(((felm_t*)Pnot->Z)[0]) 
	 && is_felm_zero(((felm_t*)Pnot->Z)[1])) {
		return ERROR;
	}
	if (is_felm_zero(((felm_t*)Qnot->Z)[0]) 
	 && is_felm_zero(((felm_t*)Qnot->Z)[1])) {
		return ERROR;
	}
}
\end{lstlisting}
\caption{Checking the order of the newly constructed basis}
\label{code:checkorder}
\end{figure}

\begin{figure}[!h]
\begin{lstlisting}
Mont_ladder(R1->x, a, aR1, Pnot, A24, CurveIsogeny->oBbits, CurveIsogeny->owordbits, CurveIsogeny);
Mont_ladder(R2->x, b, bR2, Qnot, A24, CurveIsogeny->oBbits, CurveIsogeny->owordbits, CurveIsogeny);
\end{lstlisting}
\caption{Generate a basis for $E[\lbeb]$}
\label{code:sigstruct}
\end{figure}

\begin{center}
\begin{tikzpicture}
	[scale=1, auto,
		block/.style={
		  rectangle,
		  draw=black,
		  thick,
		  fill=gray!20,
		  text width=6em,
		  align=center,
		  rounded corners,
		  minimum height=2em
		},
		blockgreen/.style={
		  rectangle,
		  draw=black,
		  thick,
		  fill=green!20,
		  text width=7.3em,
		  align=center,
		  rounded corners,
		  minimum height=2em
		},
		batchblock/.style={
		  rectangle,
		  draw=black,
		  thick,
		  fill=gray!20,
		  text width=7em,
		  align=center,
		  rounded corners,
		  minimum height=4em
		}
	]
	\draw (2.5,4.5) node[block] {\code{sign\_thread}};
	\draw[->, line width=1.0] (4,4.5) -- (4.8,4.5) node {};
	%\draw [decorate,decoration={brace,amplitude=9pt},xshift=-4pt,yshift=0pt] (4.7,3.2) -- (4.7,5.7) node [black,midway,xshift=-0.6cm,block] {\code{sign\_thread}};
	\draw (6.5,3.5) node[blockgreen] (JINV1) {\code{j\_inv\_batch}};
	\draw (6.5,4.5) node[blockgreen] (INV1) {\code{inv\_4\_way\_batch}};
	\draw (0.7, 4.5) node {1};
	
	\draw[very thick, loosely dotted] (2,3.7) -- (2,2.2) node {};
	
	\draw (2.5,1.5) node[block] {\code{sign\_thread}};
	\draw[->, line width=1.0] (4,1.5) -- (4.8,1.5) node {};
	%\draw [decorate,decoration={brace,amplitude=9pt},xshift=-4pt,yshift=0pt] (4.7,0.3) -- (4.7,2.8) node [black,midway,xshift=-0.6cm,block] {\code{sign\_thread}};
	\draw (6.5,0.5) node[blockgreen] (JINV2) {\code{j\_inv\_batch}};
	\draw (6.5,1.5) node[blockgreen] (INV2) {\code{inv\_4\_way\_batch}};
	\draw (0.7, 1.5) node {248};
	
	\draw[->, line width=1.0] (4.4,4.5) to [out=-90] (JINV1.west);
	\draw[->, line width=1.0] (4.4,1.5) to [out=-90] (JINV2.west);

	\draw [decorate,decoration={brace,amplitude=9pt},xshift=-4pt,yshift=0pt] (0.5,1) -- (0.5,5.0) node [black,midway,xshift=-0.6cm,block] {\code{isogeny\_sign}};
	
	\draw (12,3.5) node[batchblock] (BATCH1) {\code{pb\_inv}};
	\draw (12,1.5) node[batchblock] (BATCH2) {\code{pb\_inv}};
	
	\draw[->, line width=1.0] (JINV1.east) to (BATCH1.west) node {};
	\draw[->, line width=1.0] (JINV2.east) to (BATCH1.west) node {};
	\draw[->, line width=1.0] (INV1.east) to (BATCH2.west) node {};
	\draw[->, line width=1.0] (INV2.east) to (BATCH2.west) node {};
\end{tikzpicture}
\end{center}

\subsection{$\psi(S)$ Compression}

\noindent
\textit{Constructing the Basis}

\subsection{Verifying A Compressed Signature}

If we look back to the SIDH public key decompression mechanism described in Subsection \ref{subsec:costcompression}, we note again that the aim is \textit{not} to reconstruct the originally compressed values ($\pa(\genpb)$ and $\pa(\genqb)$ in \alice's case.) Instead, an instance of compressed SIDH key exchange is able to arrive at the shared secret $j(E_{\ba\rb})$ between \alice and \bob without reconstructing the original points, by absorbing the constants into the shared secret value.

And so, the C code for the decompression procedure offered by Costello et al. cannot be directly applied in our setting, as it will not reconstruct the original $\psi{S}$ value. Moreover,

\section{Results}

Our technique can reduce the size of \sidh signature compression from \_\_\_ bits to \_\_\_ bits.

\subsection{Analysis}

\subsection{Potential Performance Improvements}

could use a non-constant implementation of double and add instead of montgomery's ladder? 

